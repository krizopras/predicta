import requests
from bs4 import BeautifulSoup
import json
import re

class NesineScraper:
    def __init__(self):
        self.session = requests.Session()
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        self.base_url = "https://www.nesine.com"
    
    def get_page_content(self, url_path="/iddaa"):
        """Nesine sayfasÄ±nÄ±n iÃ§eriÄŸini Ã§ek"""
        try:
            url = f"{self.base_url}{url_path}"
            response = self.session.get(url, headers=self.headers, timeout=10)
            response.raise_for_status()
            return response.text
        except Exception as e:
            print(f"âŒ Sayfa Ã§ekme hatasÄ±: {e}")
            return None
    
    def extract_leagues_and_matches(self, html_content):
        """HTML'den lig ve maÃ§ bilgilerini Ã§Ä±kar"""
        soup = BeautifulSoup(html_content, 'html.parser')
        data = {
            "leagues": [],
            "matches": [],
            "predictions": []
        }
        
        # Ligleri Ã§Ä±kar
        self._extract_leagues(soup, data)
        
        # MaÃ§larÄ± Ã§Ä±kar
        self._extract_matches(soup, data)
        
        # Tahminleri Ã§Ä±kar
        self._extract_predictions(soup, data)
        
        return data
    
    def _extract_leagues(self, soup, data):
        """Avrupa liglerini Ã§Ä±kar"""
        # TÃ¼m metni al ve ligleri parse et
        all_text = soup.get_text()
        
        # Lig pattern'leri
        league_patterns = {
            "Premier League": ["Premier League", "hgiflere"],
            "La Liga": ["La Liga", "Epanya"],
            "Bundesliga": ["Bundesliga", "Almanya"],
            "Serie A": ["Serie A", "italya"],
            "Ligue 1": ["Ligue 1", "Fransa"],
            "SÃ¼per Lig": ["SÃ¼per Lig", "Stiger Lig", "TÃ¼rkiye"],
            "Eredivisie": ["Erotihiste", "Hollanska"],
            "Primeira Liga": ["Primeira Liga", "Portekiz"],
            "Championship": ["Championalip"]
        }
        
        for league_name, keywords in league_patterns.items():
            for keyword in keywords:
                if keyword in all_text:
                    data["leagues"].append({
                        "name": league_name,
                        "original_text": keyword,
                        "category": "AVRUPA LÄ°GLERÄ°" if league_name in [
                            "Premier League", "La Liga", "Bundesliga", 
                            "Serie A", "Ligue 1", "SÃ¼per Lig"
                        ] else "DÄ°ÄER LÄ°GLER"
                    })
                    break
    
    def _extract_matches(self, soup, data):
        """MaÃ§ bilgilerini Ã§Ä±kar"""
        # MaÃ§ elementlerini bul (nesine.com'un yapÄ±sÄ±na gÃ¶re)
        match_elements = soup.find_all(['div', 'tr'], class_=re.compile(r'match|event|game'))
        
        for element in match_elements:
            match_data = self._parse_match_element(element)
            if match_data:
                data["matches"].append(match_data)
    
    def _parse_match_element(self, element):
        """MaÃ§ elementini parse et"""
        try:
            # TakÄ±m isimlerini bul
            teams = element.find_all(['span', 'div'], class_=re.compile(r'team|name'))
            if len(teams) >= 2:
                home_team = teams[0].get_text(strip=True)
                away_team = teams[1].get_text(strip=True)
                
                # OranlarÄ± bul
                odds_elements = element.find_all(['span', 'button'], class_=re.compile(r'odd|rate|value'))
                odds = [odd.get_text(strip=True) for odd in odds_elements[:3]]  # Ä°lk 3 oran
                
                return {
                    "home_team": home_team,
                    "away_team": away_team,
                    "odds": odds,
                    "league": self._detect_league_from_teams(home_team, away_team)
                }
        except Exception as e:
            print(f"MaÃ§ parse hatasÄ±: {e}")
        return None
    
    def _detect_league_from_teams(self, home_team, away_team):
        """TakÄ±m isimlerinden lig tahmini"""
        # Bu kÄ±smÄ± takÄ±m veritabanÄ±nÄ±zla geliÅŸtirebilirsiniz
        team_leagues = {
            "Arsenal": "Premier League", "Chelsea": "Premier League",
            "Real Madrid": "La Liga", "Barcelona": "La Liga",
            "Bayern": "Bundesliga", "Dortmund": "Bundesliga",
            "Milan": "Serie A", "Inter": "Serie A",
            "Galatasaray": "SÃ¼per Lig", "FenerbahÃ§e": "SÃ¼per Lig"
        }
        
        for team, league in team_leagues.items():
            if team in home_team or team in away_team:
                return league
        
        return "Bilinmeyen Lig"
    
    def _extract_predictions(self, soup, data):
        """Tahmin bÃ¶lÃ¼mÃ¼nÃ¼ Ã§Ä±kar"""
        # "GÃ¼nÃ¼n En Ä°yi Tahminleri" bÃ¶lÃ¼mÃ¼nÃ¼ bul
        predictions_text = soup.find(string=re.compile(r"GÃ¼nÃ¼n En Ä°yi Tahminleri"))
        if predictions_text:
            prediction_section = predictions_text.find_parent()
            if prediction_section:
                # Tahmin detaylarÄ±nÄ± Ã§Ä±kar
                prediction_data = {
                    "title": "GÃ¼nÃ¼n En Ä°yi Tahminleri",
                    "analyst": "Tolgar Dine",  # Sabit gÃ¶rÃ¼nÃ¼yor
                    "content": prediction_section.get_text(strip=True)
                }
                data["predictions"].append(prediction_data)

# KullanÄ±m Ã¶rneÄŸi
def main():
    scraper = NesineScraper()
    
    # SayfayÄ± Ã§ek
    html_content = scraper.get_page_content()
    
    if html_content:
        # Verileri Ã§Ä±kar
        data = scraper.extract_leagues_and_matches(html_content)
        
        # SonuÃ§larÄ± gÃ¶ster
        print("ğŸŸ¢ LÄ°GLER:")
        for league in data["leagues"]:
            print(f"   {league['category']} - {league['name']}")
        
        print(f"\nâš½ MAÃ‡LAR ({len(data['matches'])} adet):")
        for match in data["matches"][:5]:  # Ä°lk 5 maÃ§Ä± gÃ¶ster
            print(f"   {match['home_team']} vs {match['away_team']}")
            print(f"   Oranlar: {match.get('odds', [])}")
            print(f"   Lig: {match.get('league', 'Bilinmiyor')}")
            print()
        
        print("ğŸ¯ TAHMÄ°NLER:")
        for prediction in data["predictions"]:
            print(f"   {prediction['title']} - {prediction['analyst']}")

if __name__ == "__main__":
    main()
