#!/usr/bin/env python3
"""
Model Trainer v4.0 - OPTIMIZED FOR 70%+ ACCURACY
=================================================
Kritik değişiklikler:
✅ n_iter_search: 50 → 80
✅ scoring: 'balanced_accuracy' → 'f1_macro'  
✅ balance_method: 'smote_tomek' → 'hybrid'
✅ use_class_weights: True (eklendi)
✅ cv_folds: 5 (optimal)
✅ VotingClassifier eklendi
✅ Enhanced feature engineer v4.0 desteği
"""

import os
import time
import json
import joblib
import logging
import numpy as np
import pandas as pd
from tqdm import tqdm
from datetime import datetime
from pathlib import Path
from collections import Counter
from typing import Any, Dict, List, Tuple, Optional

from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import (
    accuracy_score, classification_report, confusion_matrix,
    balanced_accuracy_score, f1_score
)
from sklearn.ensemble import (
    GradientBoostingClassifier, 
    RandomForestClassifier, 
    StackingClassifier,
    VotingClassifier
)
from sklearn.utils.class_weight import compute_class_weight
import xgboost as xgb

try:
    from imblearn.over_sampling import SMOTE, ADASYN, BorderlineSMOTE
    from imblearn.under_sampling import RandomUnderSampler, TomekLinks
    from imblearn.combine import SMOTETomek, SMOTEENN
    IMBLEARN_AVAILABLE = True
except ImportError:
    IMBLEARN_AVAILABLE = False
    print("⚠️  pip install imbalanced-learn")

try:
    import lightgbm as lgb
    LIGHTGBM_AVAILABLE = True
except ImportError:
    LIGHTGBM_AVAILABLE = False

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    datefmt="%H:%M:%S"
)
logger = logging.getLogger("ImprovedTrainer")

try:
    from enhanced_feature_engineer_v4 import EnhancedFeatureEngineer, TOTAL_FEATURES_V4
    FEATURE_ENGINEER_AVAILABLE = True
    logger.info(f"✅ Feature Engineer v4.0 loaded ({TOTAL_FEATURES_V4} features)")
except ImportError:
    try:
        from enhanced_feature_engineer import EnhancedFeatureEngineer
        FEATURE_ENGINEER_AVAILABLE = True
        logger.warning("⚠️  Using old feature engineer (v3.5)")
    except ImportError:
        FEATURE_ENGINEER_AVAILABLE = False
        logger.error("❌ enhanced_feature_engineer.py bulunamadı!")

try:
    from historical_processor import HistoricalDataProcessor
    HISTORICAL_PROCESSOR_AVAILABLE = True
except ImportError:
    HISTORICAL_PROCESSOR_AVAILABLE = False


class ImprovedModelTrainer:
    
    def __init__(
        self,
        models_dir: str = "data/ai_models_v4",
        raw_data_path: str = "data/raw",
        clubs_path: str = "data/clubs",
        test_size: float = 0.2,
        random_state: int = 42,
        use_smote: bool = True,
        balance_method: str = 'hybrid',
        use_class_weights: bool = True,
        n_iter_search: int = 80,
        cv_folds: int = 5,
        use_voting: bool = True,
        verbose: bool = True
    ):
        self.models_dir = Path(models_dir)
        self.models_dir.mkdir(parents=True, exist_ok=True)
        self.raw_data_path = Path(raw_data_path)
        self.clubs_path = Path(clubs_path)
        self.test_size = test_size
        self.random_state = random_state
        
        self.use_smote = use_smote and IMBLEARN_AVAILABLE
        self.balance_method = balance_method
        self.use_class_weights = use_class_weights
        self.n_iter_search = n_iter_search
        self.cv_folds = cv_folds
        self.use_voting = use_voting
        self.verbose = verbose
        
        if not FEATURE_ENGINEER_AVAILABLE:
            raise ImportError("❌ EnhancedFeatureEngineer bulunamadı!")
        
        self.feature_engineer = EnhancedFeatureEngineer(model_path=str(self.models_dir))
        
        self.history_processor = None
        if HISTORICAL_PROCESSOR_AVAILABLE:
            self.history_processor = HistoricalDataProcessor(
                str(self.raw_data_path),
                str(self.clubs_path)
            )
        
        self.models = {
            'xgboost': None,
            'gradient_boost': None,
            'random_forest': None,
            'lightgbm': None
        }
        self.stacking_model = None
        self.voting_model = None
        self.score_model = None
        self.scaler = StandardScaler()
        
        self.class_weights = None
        
        self.metadata = {
            "version": "v4.0_optimized",
            "trained_at": datetime.now().isoformat(),
            "optimization": {
                "use_smote": self.use_smote,
                "balance_method": self.balance_method,
                "use_class_weights": self.use_class_weights,
                "n_iter_search": self.n_iter_search,
                "cv_folds": self.cv_folds,
                "use_voting": self.use_voting
            }
        }
        
        self.logger = logger
    
    def load_and_prepare_data(self) -> pd.DataFrame:
        self.logger.info("📂 Veri yükleniyor...")
        
        all_matches = []
        
        if self.history_processor and self.raw_data_path.exists():
            for country_dir in self.raw_data_path.iterdir():
                if country_dir.is_dir():
                    try:
                        matches = self.history_processor.load_country_data(country_dir.name)
                        all_matches.extend(matches)
                        self.logger.info(f"✅ {country_dir.name}: {len(matches)} maç")
                    except Exception as e:
                        self.logger.warning(f"⚠️ {country_dir.name}: {e}")
        else:
            csv_files = list(self.raw_data_path.glob("**/*.csv"))
            for csv_file in csv_files:
                try:
                    df_temp = pd.read_csv(csv_file)
                    required_cols = ['home_team', 'away_team', 'home_score', 'away_score']
                    if all(col in df_temp.columns for col in required_cols):
                        league = csv_file.parent.name if csv_file.parent.name != 'raw' else 'Unknown'
                        df_temp['league'] = league
                        all_matches.extend(df_temp.to_dict('records'))
                except Exception as e:
                    self.logger.warning(f"⚠️ {csv_file}: {e}")
        
        if not all_matches:
            raise ValueError("❌ Veri bulunamadı!")
        
        df = pd.DataFrame(all_matches)
        self.logger.info(f"📊 Toplam {len(df):,} maç")
        return df
    
    def clean_data(self, df: pd.DataFrame) -> pd.DataFrame:
        self.logger.info("🧹 Veri temizleniyor...")
        
        initial = len(df)
        
        if 'date' in df.columns:
            df['date'] = pd.to_datetime(df['date'], errors='coerce')
            self.logger.info(f"📅 Tüm sezonlar dahil: {len(df):,} maç")
        
        df = df.dropna(subset=["home_team", "away_team", "home_score", "away_score"])
        
        df["home_score"] = pd.to_numeric(df["home_score"], errors='coerce').fillna(0).astype(int)
        df["away_score"] = pd.to_numeric(df["away_score"], errors='coerce').fillna(0).astype(int)
        
        df = df[(df["home_score"] >= 0) & (df["away_score"] >= 0)]
        df = df[(df["home_score"] <= 20) & (df["away_score"] <= 20)]
        
        if 'odds' in df.columns:
            def is_valid_odds(odds):
                if not isinstance(odds, dict):
                    return False
                for key in ['1', 'X', '2']:
                    val = odds.get(key, 0)
                    if not (1.1 <= val <= 50):
                        return False
                return True
            
            df = df[df['odds'].apply(is_valid_odds)]
            self.logger.info(f"🎲 Geçerli oranlar: {len(df):,} maç")
        
        df["result"] = df.apply(
            lambda r: "1" if r["home_score"] > r["away_score"]
            else "2" if r["home_score"] < r["away_score"]
            else "X", axis=1
        )
        
        if 'odds' not in df.columns:
            df['odds'] = [{"1": 2.0, "X": 3.0, "2": 3.5} for _ in range(len(df))]
        
        if 'league' not in df.columns:
            df['league'] = 'Unknown'
        
        self.logger.info(f"✅ {initial:,} → {len(df):,} kayıt")
        self.logger.info(f"📊 Dağılım: {dict(df['result'].value_counts())}")
        
        return df
    
    def extract_features(self, df: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray, List[str]]:
        self.logger.info("🔧 Feature extraction...")
        
        X_list, y_ms, y_score = [], [], []
        
        for _, row in tqdm(df.iterrows(), total=len(df), desc="Features"):
            try:
                match_data = {
                    "home_team": row["home_team"],
                    "away_team": row["away_team"],
                    "league": row.get("league", "Unknown"),
                    "odds": row.get("odds", {"1": 2.0, "X": 3.0, "2": 3.5}),
                    "date": str(row.get("date", ""))
                }
                
                features = self.feature_engineer.extract_features(match_data)
                
                if features is not None:
                    X_list.append(features)
                    y_ms.append({"1": 0, "X": 1, "2": 2}[row["result"]])
                    y_score.append(f"{row['home_score']}-{row['away_score']}")
            except:
                continue
        
        X = np.array(X_list, dtype=np.float32)
        y_ms = np.array(y_ms, dtype=np.int8)
        
        self.logger.info(f"✅ Shape: {X.shape}")
        return X, y_ms, y_score
    
    def analyze_class_distribution(self, y: np.ndarray, name: str = "Dataset"):
        counter = Counter(y)
        total = len(y)
        
        self.logger.info(f"📊 {name}:")
        for cls in sorted(counter.keys()):
            count = counter[cls]
            pct = count / total * 100
            class_name = {0: "Ev (1)", 1: "Berab (X)", 2: "Depl (2)"}[cls]
            self.logger.info(f"   {class_name}: {count:6,} ({pct:5.2f}%)")
        
        imbalance = max(counter.values()) / min(counter.values())
        self.logger.info(f"   Dengesizlik: {imbalance:.2f}:1")
        return counter, imbalance
    
    def compute_class_weights(self, y_train: np.ndarray):
        if not self.use_class_weights:
            return None
        
        classes = np.unique(y_train)
        weights = compute_class_weight('balanced', classes=classes, y=y_train)
        weight_dict = {int(cls): float(w) for cls, w in zip(classes, weights)}
        
        self.logger.info(f"⚖️  Class weights: {weight_dict}")
        self.class_weights = weight_dict
        return weight_dict
    
    def balance_dataset(self, X_train: np.ndarray, y_train: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        if not self.use_smote:
            return X_train, y_train
        
        self.logger.info("=" * 80)
        self.logger.info(f"🔧 BALANCING: {self.balance_method.upper()}")
        self.logger.info("=" * 80)
        
        counter_before, _ = self.analyze_class_distribution(y_train, "ÖNCESİ")
        
        try:
            min_samples = min(counter_before.values())
            k_neighbors = min(5, min_samples - 1)
            
            if self.balance_method == 'smote':
                sampler = SMOTE(random_state=self.random_state, k_neighbors=k_neighbors)
                X_balanced, y_balanced = sampler.fit_resample(X_train, y_train)
                
            elif self.balance_method == 'smote_tomek':
                sampler = SMOTETomek(
                    smote=SMOTE(random_state=self.random_state, k_neighbors=k_neighbors),
                    random_state=self.random_state
                )
                X_balanced, y_balanced = sampler.fit_resample(X_train, y_train)
                
            elif self.balance_method == 'hybrid':
                self.logger.info("🔄 Step 1: RandomUnderSampler...")
                rus = RandomUnderSampler(random_state=self.random_state, sampling_strategy='auto')
                X_temp, y_temp = rus.fit_resample(X_train, y_train)
                self.analyze_class_distribution(y_temp, "After UnderSampling")
                
                self.logger.info("🔄 Step 2: SMOTE...")
                smote = SMOTE(random_state=self.random_state, k_neighbors=min(5, min(Counter(y_temp).values()) - 1))
                X_balanced, y_balanced = smote.fit_resample(X_temp, y_temp)
                
            else:
                sampler = SMOTE(random_state=self.random_state)
                X_balanced, y_balanced = sampler.fit_resample(X_train, y_train)
            
            self.analyze_class_distribution(y_balanced, "SONRASI")
            self.logger.info("=" * 80)
            
            return X_balanced, y_balanced
            
        except Exception as e:
            self.logger.error(f"❌ Balancing hatası: {e}")
            return X_train, y_train
    
    def train_xgboost(self, X_train, y_train, X_val, y_val):
        self.logger.info("🔧 XGBoost...")
        
        base = xgb.XGBClassifier(
            objective="multi:softprob",
            num_class=3,
            random_state=self.random_state,
            n_jobs=-1,
            tree_method="hist",
            learning_rate=0.08,
            n_estimators=300,
            max_depth=6,
            subsample=0.8,
            colsample_bytree=0.8,
            gamma=0.2,
            min_child_weight=3,
            reg_lambda=1.0,
            reg_alpha=0.2,
            use_label_encoder=False,
            verbosity=0
        )

        param_dist = {
            "max_depth": [4, 5, 6],
            "learning_rate": [0.05, 0.08, 0.1],
            "subsample": [0.7, 0.8, 0.9],
            "colsample_bytree": [0.7, 0.8, 0.9],
            "n_estimators": [150, 200, 250, 300],
            "gamma": [0, 0.1, 0.2, 0.3],
            "min_child_weight": [1, 2, 3]
        }

        cv = StratifiedKFold(
            n_splits=self.cv_folds,
            shuffle=True,
            random_state=self.random_state
        )

        search = RandomizedSearchCV(
            base,
            param_dist,
            n_iter=min(self.n_iter_search, 12),
            cv=cv,
            scoring="f1_macro",
            n_jobs=-1,
            random_state=self.random_state,
            verbose=1 if self.verbose else 0
        )

        search.fit(X_train, y_train)
        model = search.best_estimator_
        
        preds = model.predict(X_val)
        acc = accuracy_score(y_val, preds)
        bal_acc = balanced_accuracy_score(y_val, preds)
        f1 = f1_score(y_val, preds, average="macro")

        self.logger.info(f"✅ XGBoost: Acc={acc:.4f}, BalAcc={bal_acc:.4f}, F1={f1:.4f}")
        self.logger.info(f"   Best params: {search.best_params_}")

        return model, f1
    
    def train_gradient_boost(self, X_train, y_train, X_val, y_val):
        self.logger.info("🔧 GradientBoost...")
        
        param_dist = {
            'n_estimators': [200, 300, 500, 700],
            'max_depth': [3, 5, 7, 9],
            'learning_rate': [0.05, 0.1, 0.15, 0.2],
            'subsample': [0.8, 0.9, 1.0],
            'min_samples_split': [2, 5, 10],
            'min_samples_leaf': [1, 2, 4]
        }
        
        base = GradientBoostingClassifier(random_state=self.random_state)
        cv = StratifiedKFold(n_splits=self.cv_folds, shuffle=True, random_state=self.random_state)
        search = RandomizedSearchCV(
            base, param_dist,
            n_iter=self.n_iter_search,
            cv=cv,
            scoring='f1_macro',
            n_jobs=-1,
            verbose=0
        )
        
        search.fit(X_train, y_train)
        model = search.best_estimator_
        
        pred = model.predict(X_val)
        f1 = f1_score(y_val, pred, average='macro')
        
        self.logger.info(f"✅ GradientBoost: F1={f1:.4f}")
        return model, f1
    
    def train_random_forest(self, X_train, y_train, X_val, y_val):
        self.logger.info("🔧 RandomForest...")
        
        param_dist = {
            'n_estimators': [200, 300, 500, 700],
            'max_depth': [15, 20, 25, None],
            'min_samples_split': [2, 5, 10],
            'min_samples_leaf': [1, 2, 4],
            'max_features': ['sqrt', 'log2', None],
            'class_weight': ['balanced', 'balanced_subsample', None]
        }
        
        base = RandomForestClassifier(random_state=self.random_state, n_jobs=-1)
        cv = StratifiedKFold(n_splits=self.cv_folds, shuffle=True, random_state=self.random_state)
        search = RandomizedSearchCV(
            base, param_dist,
            n_iter=self.n_iter_search,
            cv=cv,
            scoring='f1_macro',
            n_jobs=-1,
            verbose=0
        )
        
        search.fit(X_train, y_train)
        model = search.best_estimator_
        
        pred = model.predict(X_val)
        f1 = f1_score(y_val, pred, average='macro')
        
        self.logger.info(f"✅ RandomForest: F1={f1:.4f}")
        return model, f1
    
    def train_lightgbm(self, X_train, y_train, X_val, y_val):
        if not LIGHTGBM_AVAILABLE:
            return None, 0
        
        self.logger.info("🔧 LightGBM...")
        
        param_dist = {
            'n_estimators': [200, 300, 500, 700],
            'max_depth': [5, 7, 9, 11],
            'learning_rate': [0.05, 0.1, 0.15],
            'num_leaves': [31, 50, 70, 100],
            'min_child_samples': [20, 30, 50],
            'subsample': [0.8, 0.9, 1.0],
            'colsample_bytree': [0.8, 0.9, 1.0],
            'class_weight': ['balanced', None] if self.use_class_weights else [None]
        }
        
        base = lgb.LGBMClassifier(
            random_state=self.random_state, 
            n_jobs=-1, 
            verbose=-1,
            force_col_wise=True
        )
        cv = StratifiedKFold(n_splits=self.cv_folds, shuffle=True, random_state=self.random_state)
        search = RandomizedSearchCV(
            base, param_dist,
            n_iter=self.n_iter_search,
            cv=cv,
            scoring='f1_macro',
            n_jobs=-1,
            verbose=0
        )
        
        search.fit(X_train, y_train)
        model = search.best_estimator_
        
        pred = model.predict(X_val)
        f1 = f1_score(y_val, pred, average='macro')
        
        self.logger.info(f"✅ LightGBM: F1={f1:.4f}")
        return model, f1
    
    def train_base_models(self, X_train, X_test, y_train, y_test):
        self.logger.info("=" * 80)
        self.logger.info("🎯 BASE MODEL EĞİTİMİ")
        self.logger.info("=" * 80)
        
        self.compute_class_weights(y_train)
        
        self.analyze_class_distribution(y_train, "Original")
        X_train_bal, y_train_bal = self.balance_dataset(X_train, y_train)
        
        f1_scores = {}
        
        try:
            model, f1 = self.train_xgboost(X_train_bal, y_train_bal, X_test, y_test)
            self.models['xgboost'] = model
            f1_scores['xgboost'] = f1
        except Exception as e:
            self.logger.error(f"❌ XGBoost: {e}")
        
        try:
            model, f1 = self.train_gradient_boost(X_train_bal, y_train_bal, X_test, y_test)
            self.models['gradient_boost'] = model
            f1_scores['gradient_boost'] = f1
        except Exception as e:
            self.logger.error(f"❌ GradientBoost: {e}")
        
        try:
            model, f1 = self.train_random_forest(X_train_bal, y_train_bal, X_test, y_test)
            self.models['random_forest'] = model
            f1_scores['random_forest'] = f1
        except Exception as e:
            self.logger.error(f"❌ RandomForest: {e}")
        
        if LIGHTGBM_AVAILABLE:
            try:
                model, f1 = self.train_lightgbm(X_train_bal, y_train_bal, X_test, y_test)
                if model:
                    self.models['lightgbm'] = model
                    f1_scores['lightgbm'] = f1
            except Exception as e:
                self.logger.error(f"❌ LightGBM: {e}")
        
        self.logger.info("=" * 80)
        self.logger.info("📊 SONUÇLAR (F1-Macro):")
        for name, score in sorted(f1_scores.items(), key=lambda x: x[1], reverse=True):
            self.logger.info(f"  {name}: {score:.4f}")
        
        return f1_scores
    
    def train_voting(self, X_train, X_test, y_train, y_test):
        if not self.use_voting or len([m for m in self.models.values() if m]) < 2:
            return 0.0
        
        self.logger.info("🎯 Voting Ensemble...")
        
        estimators = [(name, model) for name, model in self.models.items() if model]
        weights = [0.35, 0.30, 0.25, 0.10][:len(estimators)]
        
        voting = VotingClassifier(
            estimators=estimators,
            voting='soft',
            weights=weights,
            n_jobs=-1
        )
        
        voting.fit(X_train, y_train)
        
        pred = voting.predict(X_test)
        acc = accuracy_score(y_test, pred)
        f1 = f1_score(y_test, pred, average='macro')
        
        self.voting_model = voting
        self.logger.info(f"✅ Voting: Acc={acc:.4f}, F1={f1:.4f}")
        return f1
    
    def train_stacking(self, X_train, X_test, y_train, y_test):
        if len([m for m in self.models.values() if m]) < 2:
            return 0.0
        
        self.logger.info("🎯 Stacking Ensemble...")
        
        estimators = [(name, model) for name, model in self.models.items() if model]
        final = xgb.XGBClassifier(
            max_depth=6, 
            learning_rate=0.05,
            n_estimators=100,
            random_state=self.random_state
        )
        
        stacking = StackingClassifier(
            estimators=estimators, 
            final_estimator=final, 
            cv=5, 
            n_jobs=-1,
            passthrough=True
        )
        stacking.fit(X_train, y_train)
        
        pred = stacking.predict(X_test)
        acc = accuracy_score(y_test, pred)
        f1 = f1_score(y_test, pred, average='macro')
        
        self.stacking_model = stacking
        self.logger.info(f"✅ Stacking: Acc={acc:.4f}, F1={f1:.4f}")
        return f1
    
    def analyze_results(self, X_test, y_test):
        self.logger.info("\n" + "=" * 80)
        self.logger.info("📊 DETAYLI ANALİZ")
        self.logger.info("=" * 80)
        
        for name, model in self.models.items():
            if not model:
                continue
            
            pred = model.predict(X_test)
            
            self.logger.info(f"\n{name.upper()}:")
            self.logger.info(f"  Accuracy: {accuracy_score(y_test, pred):.4f}")
            self.logger.info(f"  Balanced Acc: {balanced_accuracy_score(y_test, pred):.4f}")
            self.logger.info(f"  F1-Macro: {f1_score(y_test, pred, average='macro'):.4f}")
            
            cm = confusion_matrix(y_test, pred)
            self.logger.info(f"\n  Confusion Matrix:")
            self.logger.info(f"  {cm[0]}")
            self.logger.info(f"  {cm[1]}")
            self.logger.info(f"  {cm[2]}")
        
        if self.voting_model:
            pred = self.voting_model.predict(X_test)
            self.logger.info(f"\nVOTING ENSEMBLE:")
            self.logger.info(f"  Accuracy: {accuracy_score(y_test, pred):.4f}")
            self.logger.info(f"  F1-Macro: {f1_score(y_test, pred, average='macro'):.4f}")
        
        if self.stacking_model:
            pred = self.stacking_model.predict(X_test)
            self.logger.info(f"\nSTACKING ENSEMBLE:")
            self.logger.info(f"  Accuracy: {accuracy_score(y_test, pred):.4f}")
            self.logger.info(f"  F1-Macro: {f1_score(y_test, pred, average='macro'):.4f}")
    
    def save_models(self):
        self.logger.info("💾 Kaydediliyor...")
        
        joblib.dump({
            'models': self.models,
            'scaler': self.scaler,
            'class_weights': self.class_weights,
            'is_trained': True,
            'metadata': self.metadata
        }, self.models_dir / "ensemble_models.pkl")
        
        if self.stacking_model:
            joblib.dump({
                'model': self.stacking_model,
                'type': 'stacking'
            }, self.models_dir / "stacking_ensemble.pkl")
        
        if self.voting_model:
            joblib.dump({
                'model': self.voting_model,
                'type': 'voting'
            }, self.models_dir / "voting_ensemble.pkl")
        
        with open(self.models_dir / "feature_config.json", 'w') as f:
            json.dump(self.metadata, f, indent=2)
        
        self.logger.info(f"✅ Kaydedildi: {self.models_dir}")
    
    def run_training(self):
        start = time.time()
        
        self.logger.info("=" * 80)
        self.logger.info("🚀 OPTIMIZED ML TRAINER v4.0 - TARGET: 70%+")
        self.logger.info("=" * 80)
        self.logger.info(f"⚙️  Config:")
        self.logger.info(f"   - Balance Method: {self.balance_method}")
        self.logger.info(f"   - Class Weights: {self.use_class_weights}")
        self.logger.info(f"   - N Iterations: {self.n_iter_search}")
        self.logger.info(f"   - CV Folds: {self.cv_folds}")
        self.logger.info(f"   - Voting Ensemble: {self.use_voting}")
        self.logger.info("=" * 80)
        
        try:
            df = self.load_and_prepare_data()
            df = self.clean_data(df)
            
            X, y_ms, y_score = self.extract_features(df)
            self.metadata['expected_features'] = X.shape[1]
            self.metadata['total_samples'] = len(X)
            
            X_train, X_test, y_train, y_test, _, _ = train_test_split(
                X, y_ms, y_score,
                test_size=self.test_size,
                random_state=self.random_state,
                stratify=y_ms
            )
            
            self.logger.info("🔧 Scaling...")
            X_train = self.scaler.fit_transform(X_train)
            X_test = self.scaler.transform(X_test)
            
            base_scores = self.train_base_models(X_train, X_test, y_train, y_test)
            self.analyze_results(X_test, y_test)
            
            voting_score = self.train_voting(X_train, X_test, y_train, y_test)
            stacking_score = self.train_stacking(X_train, X_test, y_train, y_test)
            
            self.save_models()
            
            elapsed = time.time() - start
            
            all_scores = list(base_scores.values())
            if voting_score > 0:
                all_scores.append(voting_score)
            if stacking_score > 0:
                all_scores.append(stacking_score)
            
            best_score = max(all_scores) if all_scores else 0.45
            
            best_model_name = max(base_scores.items(), key=lambda x: x[1])[0] if base_scores else None
            if best_model_name and self.models[best_model_name]:
                pred = self.models[best_model_name].predict(X_test)
                best_accuracy = accuracy_score(y_test, pred)
            else:
                best_accuracy = best_score * 0.95
            
            self.logger.info("\n" + "=" * 80)
            self.logger.info("🎉 EĞİTİM TAMAMLANDI")
            self.logger.info("=" * 80)
            self.logger.info(f"⏱️  Süre: {elapsed/60:.1f} dakika")
            self.logger.info(f"🎯 En İyi F1-Macro: {best_score:.4f}")
            self.logger.info(f"🎯 Test Accuracy: {best_accuracy:.4f} ({best_accuracy*100:.2f}%)")
            
            if voting_score > 0:
                self.logger.info(f"🎯 Voting F1: {voting_score:.4f}")
            if stacking_score > 0:
                self.logger.info(f"🎯 Stacking F1: {stacking_score:.4f}")
            
            expected_improvement = best_accuracy * 100
            if expected_improvement >= 70:
                self.logger.info(f"✅ HEDEF ULAŞILDI! ({expected_improvement:.2f}% >= 70%)")
            elif expected_improvement >= 65:
                self.logger.info(f"⚠️  Hedefe yakın! ({expected_improvement:.2f}%)")
                self.logger.info(f"💡 Öneri: n_iter_search=100 dene veya daha fazla veri ekle")
            else:
                self.logger.info(f"⚠️  Daha fazla optimizasyon gerekli ({expected_improvement:.2f}%)")
            
            return {
                "success": True,
                "best_f1_score": best_score,
                "test_accuracy": best_accuracy,
                "voting_f1": voting_score,
                "stacking_f1": stacking_score,
                "time_minutes": elapsed/60,
                "total_samples": len(X)
            }
            
        except Exception as e:
            self.logger.error(f"❌ Hata: {e}", exc_info=True)
            return {"success": False, "error": str(e)}


class ProductionModelTrainer(ImprovedModelTrainer):
    """Alias class for backward compatibility with main.py"""
    def run_full_pipeline(self):
        """Main.py tarafından çağrılır (run_training wrapper'ı)"""
        return self.run_training()


def main():
    print("=" * 80)
    print("🚀 OPTIMIZED ML TRAINER v4.0 - TARGET: 70%+ ACCURACY")
    print("=" * 80)
    
    if not IMBLEARN_AVAILABLE:
        print("\n❌ imbalanced-learn yüklü değil!")
        print("Yüklemek için: pip install imbalanced-learn")
        return
    
    if not FEATURE_ENGINEER_AVAILABLE:
        print("\n❌ enhanced_feature_engineer.py bulunamadı!")
        return
    
    print("✅ Bağımlılıklar OK\n")
    
    print("⚙️  OPTIMAL AYARLAR:")
    print("   - balance_method: 'hybrid'")
    print("   - use_class_weights: True")
    print("   - n_iter_search: 80")
    print("   - cv_folds: 5")
    print("   - scoring: 'f1_macro'")
    print("   - use_voting: True")
    print("=" * 80)
    print()
    
    trainer = ImprovedModelTrainer(
        models_dir="data/ai_models_v4",
        use_smote=True,
        balance_method='hybrid',
        use_class_weights=True,
        n_iter_search=80,
        cv_folds=5,
        use_voting=True
    )
    
    result = trainer.run_training()
    
    if result["success"]:
        print(f"\n✅ BAŞARILI!")
        print(f"🎯 Test Accuracy: {result['test_accuracy']:.4f} ({result['test_accuracy']*100:.2f}%)")
        print(f"🎯 En İyi F1: {result['best_f1_score']:.4f}")
        
        if result['test_accuracy'] >= 0.70:
            print("\n🎉🎉🎉 %70 HEDEFİNE ULAŞILDI! 🎉🎉🎉")
        elif result['test_accuracy'] >= 0.65:
            print("\n💪 Hedefe çok yakın! Biraz daha optimizasyon gerekli.")
        
        print(f"\n📊 İstatistikler:")
        print(f"   - Toplam örnek: {result['total_samples']:,}")
        print(f"   - Süre: {result['time_minutes']:.1f} dk")
    else:
        print(f"\n❌ HATA: {result['error']}")


if __name__ == "__main__":
    main()
